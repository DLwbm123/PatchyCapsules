{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#import pydevd\n",
    "#pydevd.settrace('localhost', port=49309, stdoutToServer=True, stderrToServer=True)\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, defaultdict\n",
    "from six.moves import xrange\n",
    "#from __pynauty__ import graph\n",
    "#import pynauty.graph\n",
    "import pynauty\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pynauty as nauty\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "\n",
    "\n",
    "from PatchyTools import Dataset, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "#Node id is made to start from 0 due to nauty package requirement, even if it starts from 1 in the original\n",
    "#Graph id is starting from 1\n",
    "'''\n",
    "\n",
    "mutag = Dataset.dropbox('MUTAG')\n",
    "df_edge_label = mutag.get_edge_label()\n",
    "df_graph_ind = mutag.get_graph_ind()\n",
    "df_adj = mutag.get_adj()\n",
    "\n",
    "df_node_label = mutag.get_node_label()\n",
    "df_node_label = pd.concat([df_node_label, df_graph_ind.graph_label], axis=1)\n",
    "\n",
    "del df_graph_ind\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_subset_adj(df_adj, df_node_label,graph_label_num):\n",
    "    df_glabel = df_node_label[df_node_label.graph_label == graph_label_num ]\n",
    "    index_of_glabel = (df_adj['to'].isin(df_glabel.node) & df_adj['from'].isin(df_glabel.node))\n",
    "    return df_adj[index_of_glabel]\n",
    "\n",
    "def get_smallest_node_id_from_adj(df_adj):\n",
    "    return min(df_adj['to'].min(), df_adj['from'].min())\n",
    "\n",
    "\n",
    "def create_adj_dict_by_graphId(df_adj, df_node_label):\n",
    "    '''\n",
    "    input: df_node_label\n",
    "    return: {1: {0:[0,2,5]}} = {graphId: {nodeId:[node,node,node]}}\n",
    "    '''\n",
    "    adj_dict_by_graphId ={}\n",
    "    unique_graph_labels = df_node_label.graph_label.unique()\n",
    "    for l in unique_graph_labels:\n",
    "        df_subset_adj = get_subset_adj(df_adj, df_node_label, graph_label_num=l)        \n",
    "        smallest_node_id = get_smallest_node_id_from_adj(df_subset_adj)\n",
    "        df_subset_adj -= smallest_node_id\n",
    "        adj_dict_by_graphId[l] = df_subset_adj\n",
    "    return adj_dict_by_graphId\n",
    "\n",
    "\n",
    "def canonical_labeling(adj_dict_by_graphId, df_node_label, df_adj):\n",
    "    all_canonical_labels =[]\n",
    "    unique_graph_labels = df_node_label.graph_label.unique()\n",
    "    for l in unique_graph_labels:\n",
    "        df_subset_adj = adj_dict_by_graphId[l]\n",
    "        df_subset_nodes = df_node_label[df_node_label.graph_label==l]        \n",
    "        temp_graph_dict = utils.dfadj_to_dict(df_subset_adj)\n",
    "        nauty_graph = nauty.Graph(len(temp_graph_dict), adjacency_dict=temp_graph_dict)\n",
    "        canonical_labeling = nauty.canonical_labeling(nauty_graph)        \n",
    "        canonical_labeling = [df_subset_nodes.label.values[i] for i in canonical_labeling] ###\n",
    "        all_canonical_labels += canonical_labeling\n",
    "    return all_canonical_labels\n",
    "\n",
    "\n",
    "def create_adj_coomatrix_by_graphId(adj_dict_by_graphId, df_node_label):\n",
    "    \"\"\"\n",
    "    return: a coomatrix per graphId\n",
    "    \"\"\"\n",
    "    \n",
    "    adj_coomatrix_by_graphId ={}\n",
    "    unique_graph_labels = df_node_label.graph_label.unique()\n",
    "    for l in unique_graph_labels:\n",
    "        df_subset_adj = adj_dict_by_graphId[l]\n",
    "        df_subset_node_label = df_node_label[df_node_label.graph_label == l]\n",
    "        adjacency = coo_matrix(( np.ones(len(df_subset_adj)), \n",
    "                                (df_subset_adj.iloc[:,0].values, df_subset_adj.iloc[:,1].values) ), \n",
    "                                 shape=(len(df_subset_node_label), len(df_subset_node_label))\n",
    "                              )\n",
    "        adj_coomatrix_by_graphId[l]=adjacency\n",
    "    return adj_coomatrix_by_graphId\n",
    "\n",
    "def make_naighbor(adj_coomatrix_by_graphId, df_node_label):\n",
    "    \n",
    "    \"\"\"\n",
    "    return: a dictionary with the shape of {graphId:[matrix: node x neighbor]} \n",
    "    The size of 2D matrix is (Node number) x (NEIGHBOR_SIZE). \n",
    "    \"\"\"\n",
    "    \n",
    "    neighborhoods_dict={}\n",
    "    \n",
    "    unique_graph_labels = df_node_label.graph_label.unique()\n",
    "    for l in unique_graph_labels:\n",
    "        adjacency = adj_coomatrix_by_graphId[l]\n",
    "        graph = nx.from_numpy_matrix(adjacency.todense())\n",
    "        \n",
    "        neighborhoods = np.zeros((adjacency.shape[0], NEIGHBOR_SIZE), dtype=np.int32)\n",
    "        # If the NEIGHBOR_SIZE exceeds the number of actual neighbor nodes, then fill them with -1\n",
    "        neighborhoods.fill(-1) \n",
    "        \n",
    "        df_sequence = df_node_label[df_node_label.graph_label == l]\n",
    "        df_sequence = df_sequence.sort_values(by='cano_label')\n",
    "        smallest_node_id = df_sequence.node.min()\n",
    "                \n",
    "        # CUT GRAPH BY THRESHOLD of cano_label\n",
    "        df_sequence = df_sequence.loc[df_sequence.cano_label <= LABEL_THRESHOLD]\n",
    "        df_sequence['node'] = df_sequence.node.values  - smallest_node_id        \n",
    "        \n",
    "        for i, node in enumerate(df_sequence.node):\n",
    "            shortest = nx.single_source_dijkstra_path_length(graph, node).items()\n",
    "            shortest = sorted(shortest, key=lambda v: v[1])\n",
    "            shortest = shortest[:NEIGHBOR_SIZE]\n",
    "            for j in range(0, min(NEIGHBOR_SIZE, len(shortest))):\n",
    "                neighborhoods[i][j] = shortest[j][0]\n",
    "        \n",
    "        neighborhoods_dict[l] = neighborhoods.copy()\n",
    "    return neighborhoods_dict\n",
    "\n",
    "print('start canonical_labeling')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main (Timing starts here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM_NODES \n",
    "LABEL_THRESHOLD = 2 #threshold of canonical label\n",
    "NEIGHBOR_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dict_by_graphId = create_adj_dict_by_graphId(df_adj, df_node_label)\n",
    "cano_label = canonical_labeling(adj_dict_by_graphId, df_node_label, df_adj)\n",
    "df_node_label = pd.concat([df_node_label, pd.Series(cano_label, dtype=int, name='cano_label')],  axis=1)\n",
    "\n",
    "now = time.time()\n",
    "#cert_list = [i for i in (nauty.certificate(nauty_graph))]\n",
    "# '''canonical_labeling = [df_node_label.label.values[i] for i in canonical_labeling]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Show the frequency of labels to make threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node_label.cano_label.value_counts().plot(kind='bar')\n",
    "df_node_label.cano_label.value_counts().sort_index().plot(kind='bar',  figsize=(14,5))\n",
    "\n",
    "plt.title('Number of nodes by labeling')\n",
    "plt.xlabel('Labeling')\n",
    "plt.ylabel('Number of nodes')\n",
    "\n",
    "_SUM_ALL_NODES = df_node_label.shape[0]\n",
    "\n",
    "plt.twinx()\n",
    "plt.ylabel(\"Cummlative Sum Rate\", color=\"r\")\n",
    "plt.tick_params(axis=\"y\", labelcolor=\"r\")\n",
    "plt.plot(df_node_label.cano_label.value_counts().sort_index().index, \n",
    "         df_node_label.cano_label.value_counts().sort_index().cumsum() /_SUM_ALL_NODES, \"r-\", linewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get several nodes with a condition of cano_label (sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_coomatrix_by_graphId = create_adj_coomatrix_by_graphId(adj_dict_by_graphId, df_node_label)\n",
    "neighborhoods_graph = make_naighbor(adj_coomatrix_by_graphId, df_node_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things about tensorflow constraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "neighborhoods[graphId]: This represents the matrix of (nodes x neighbor).\n",
    "nodes: This represents the matrix of (nodes x features).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = df_node_label['label'].unique()\n",
    "num_features = len(feature_list)\n",
    "\n",
    "\n",
    "graph_id =1\n",
    "def main_timing(graph_id):\n",
    "    neighborhoods = tf.constant(neighborhoods_graph[graph_id], dtype=tf.int32)\n",
    "    sparse_df = pd.get_dummies(df_node_label.loc[df_node_label.graph_label==graph_id].label, \n",
    "                               columns=feature_list,\n",
    "                               sparse=True\n",
    "                              )\n",
    "    \n",
    "    #### Reindex and transporse to get columns of get dummy #########\n",
    "    sparse_df = sparse_df.T.reindex(feature_list).T.fillna(0)\n",
    "    \n",
    "    nodes = tf.constant(\n",
    "        sparse_df.values,\n",
    "        dtype=tf.int32 )\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        data = tf.reshape(neighborhoods, [-1])\n",
    "        i = tf.maximum(data, 0)\n",
    "        i_list = i.eval()\n",
    "        #print(i_list)\n",
    "        #print('')\n",
    "\n",
    "        for ind, i in enumerate(i_list):\n",
    "            if ind ==0: \n",
    "                positive = tf.strided_slice(nodes, [i], [i+1], [1])\n",
    "                #positive = tf.constant(temp)\n",
    "            else:\n",
    "                temp = tf.strided_slice(nodes, [i], [i+1], [1])\n",
    "                positive = tf.concat([positive,temp],axis=0)\n",
    "\n",
    "        negative = tf.zeros([positive.shape[0], positive.shape[1]], dtype= tf.int32)\n",
    "\n",
    "        #print ('shape', data.shape, negative.shape, positive.shape)\n",
    "        #print ( data, negative, positive)\n",
    "\n",
    "        # padding with 0 here because -1 indicates there is no neighbor nodes.\n",
    "        ret = tf.where(data < 0, negative, positive)\n",
    "        #print('padding done')\n",
    "\n",
    "\n",
    "        ret = tf.reshape(ret, \n",
    "                         [neighborhoods.shape[0], \n",
    "                          NEIGHBOR_SIZE, # This is equals to neighborhoods.shape[1]\n",
    "                          num_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(adj_dict_by_graphId.keys()):\n",
    "    main_timing(key)\n",
    "    \n",
    "print ('time passed in seconds', (\"%.2f\" % atime.time() - now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
