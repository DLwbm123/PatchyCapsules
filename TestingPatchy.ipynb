{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#import pydevd\n",
    "#pydevd.settrace('localhost', port=49309, stdoutToServer=True, stderrToServer=True)\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, defaultdict\n",
    "from six.moves import xrange\n",
    "#from __pynauty__ import graph\n",
    "#import pynauty.graph\n",
    "import pynauty\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pynauty as nauty\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('PatchyTools')\n",
    "sys.path.append('../PatchyCapsules/')\n",
    "from utils_caps import load_image_data\n",
    "import tensorflow as tf\n",
    "from numpy import random as nprand\n",
    "\n",
    "from CapsuleNetwork import CapsuleNetwork\n",
    "from utils_caps import load_image_data,subsample\n",
    "from DropboxLoader import DropboxLoader\n",
    "%matplotlib inline\n",
    "\n",
    "from GraphConverter import GraphConverter\n",
    "from PatchyTools import utils\n",
    "from PatchyTools import Patchy_san\n",
    "from Patchy_san import dfadj_to_dict\n",
    "from Patchy_san import canonical_labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape :  (10000, 32, 32, 3)\n",
      "shape :  (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Path to data:\n",
    "train_file_path = '../../others/CIFAR10-img-classification-tensorflow/cifar-10-batches-py/data_batch_1'\n",
    "test_file_path = '../../others/CIFAR10-img-classification-tensorflow/cifar-10-batches-py/test_batchs'\n",
    "X_train, y_train = load_image_data(train_file_path)\n",
    "X_test, y_test = load_image_data(train_file_path)\n",
    "X_train,y_train = subsample(X_train, y_train)\n",
    "X_test, y_test = subsample(X_test, y_test)\n",
    "\n",
    "# Constants:\n",
    "batch_size = 100\n",
    "height, width, num_channels = X_train.shape[1:]\n",
    "num_inputs = height * width\n",
    "num_outputs = 10\n",
    "num_iter = 5\n",
    "caps = CapsuleNetwork(batch_size,num_inputs,num_outputs,num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.6.0\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow Version: {}'.format(tf.__version__)) \n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "#Node id is made to start from 0 due to nauty package requirement, even if it starts from 1 in the original\n",
    "#Graph id is starting from 1\n",
    "'''\n",
    "\n",
    "\n",
    "mutag = DropboxLoader('MUTAG')\n",
    "\n",
    "df_edge_label = mutag.get_edge_label()\n",
    "df_graph_ind = mutag.get_graph_ind()\n",
    "df_adj = mutag.get_adj()\n",
    "# Getting the\n",
    "df_node_label = mutag.get_node_label()\n",
    "df_node_label = pd.concat([df_node_label, df_graph_ind.graph_ind], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Patchy_san import create_adj_dict_by_graphId\n",
    "from Patchy_san import get_smallest_node_id_from_adj\n",
    "from Patchy_san import get_subset_adj\n",
    "from Patchy_san import create_adj_coomatrix_by_graphId\n",
    "from Patchy_san import canonical_labeling\n",
    "from Patchy_san import make_neighbor\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjeceny dict and \n",
    "adj_dict = create_adj_dict_by_graphId(df_adj, df_node_label)\n",
    "adj_coomatrix_by_graphId = create_adj_coomatrix_by_graphId(adj_dict, df_node_label)\n",
    "cano_label = canonical_labeling(adj_dict, df_node_label, df_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = df_node_label['label'].unique()\n",
    "nodes_features = pd.get_dummies(df_node_label.label,\n",
    "                                columns=feature_list,\n",
    "                                sparse=True)\n",
    "nodes_features = nodes_features.T.reindex(feature_list).T.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MUTAG'\n",
    "width = 18\n",
    "receptive_field = 10\n",
    "PatchyConverter = GraphConverter(dataset_name, width, receptive_field)\n",
    "mutag_tensor = PatchyConverter.graphs_to_Patchy_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dictionary of graphs\n",
      "Canonical Labeling\n",
      "Getting the Neighboors \n",
      "Neighboors to Tensor\n"
     ]
    }
   ],
   "source": [
    "g1 = nx.Graph()\n",
    "g1.add_edges_from(adj_1.values)\n",
    "nx.draw(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 180, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutag_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = nx.Graph()\n",
    "g1.add_edges_from(adj_dict[1].values)\n",
    "nx.draw(g1,with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nauty_graph = nauty.Graph(len(temp_graph_dict), adjacency_dict=temp_graph_dict)\n",
    "test_canon_label = nauty.canonical_labeling(nauty_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_2 = [df_subset_nodes.label.values[i] for i in test_canon_label]  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_canon_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_node_label2 = pd.concat([df_node_label, pd.Series(cano_label, dtype=int, name='cano_label')], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_graph_labels = df_node_label.graph_ind.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjacency = adj_coomatrix_by_graphId[1]\n",
    "graph = nx.from_numpy_matrix(adjacency.todense())\n",
    "\n",
    "# Create the neighbors with -1 for neighbor assemble.\n",
    "#After this, if the RECEPTIVE_FIELD_SIZE_K exceeds the number of WIDTH_W, then fill them with -1\n",
    "neighborhoods = np.zeros((18, 10), dtype=np.int32)\n",
    "neighborhoods.fill(-1)\n",
    "\n",
    "df_sequence = df_node_label[df_node_label.graph_ind == 1]\n",
    "df_sequence = df_sequence.sort_values(by='cano_label')\n",
    "smallest_node_id = df_sequence.node.min()\n",
    "\n",
    "# CUT GRAPH BY THRESHOLD of cano_label ''' Top width w elements of V according to labeling  '''\n",
    "df_sequence = df_sequence.iloc[:18,:]\n",
    "df_sequence['node'] = df_sequence.node.values  - smallest_node_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_shortest = pd.DataFrame.from_dict(nx.single_source_dijkstra_path_length(graph, 8),orient='index') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RECEPTIVE_FIELD_SIZE_K =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_shortest.columns =['distance'] #\n",
    "df_shortest['node'] = df_shortest.index.values #\n",
    "df_shortest = pd.merge(df_node_label, df_shortest, on='node', how='right') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort by distance and then by cano_label\n",
    "df_shortest = df_shortest.sort_values(by=['distance','cano_label']) #\n",
    "df_shortest = df_shortest.iloc[:10,:] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j in range(0, min(RECEPTIVE_FIELD_SIZE_K, len(df_shortest))):\n",
    "    #neighborhoods[i][j] = shortest[j][0]\n",
    "    neighborhoods[8][j] = df_shortest['node'].values[j] + smallest_node_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH_W = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_graph_labels = df_node_label.graph_ind.unique()\n",
    "for l_ind, l in zip([0],[1]):#enumerate(unique_graph_labels):\n",
    "    adjacency = adj_coomatrix_by_graphId[l]\n",
    "    graph = nx.from_numpy_matrix(adjacency.todense())\n",
    "\n",
    "    # Create the neighbors with -1 for neighbor assemble.\n",
    "    #After this, if the RECEPTIVE_FIELD_SIZE_K exceeds the number of WIDTH_W, then fill them with -1\n",
    "    neighborhoods = np.zeros((WIDTH_W, RECEPTIVE_FIELD_SIZE_K), dtype=np.int32)\n",
    "    neighborhoods.fill(-1)\n",
    "\n",
    "    df_sequence = df_node_label[df_node_label.graph_ind == l]\n",
    "    df_sequence = df_sequence.sort_values(by='cano_label')\n",
    "    smallest_node_id = df_sequence.node.min()\n",
    "\n",
    "    # CUT GRAPH BY THRESHOLD of cano_label ''' Top width w elements of V according to labeling  '''\n",
    "    df_sequence = df_sequence.iloc[:WIDTH_W,:]\n",
    "    df_sequence['node'] = df_sequence.node.values  - smallest_node_id\n",
    "\n",
    "    for i, node in enumerate(df_sequence.node):\n",
    "        #shortest = nx.single_source_dijkstra_path_length(graph, node).items()\n",
    "        df_shortest = pd.DataFrame.from_dict(nx.single_source_dijkstra_path_length(graph, node),\n",
    "                                             orient='index') #\n",
    "        df_shortest.columns =['distance'] #\n",
    "        df_shortest['node'] = df_shortest.index.values #\n",
    "        df_shortest = pd.merge(df_node_label, df_shortest, on='node', how='right') #\n",
    "\n",
    "        # Sort by distance and then by cano_label\n",
    "        df_shortest = df_shortest.sort_values(by=['distance','cano_label']) #\n",
    "        df_shortest = df_shortest.iloc[:RECEPTIVE_FIELD_SIZE_K,:] #\n",
    "        #shortest = sorted(shortest, key=lambda v: v[1])\n",
    "        #shortest = shortest[:RECEPTIVE_FIELD_SIZE_K]\n",
    "        for j in range(0, min(RECEPTIVE_FIELD_SIZE_K, len(df_shortest))):\n",
    "            #neighborhoods[i][j] = shortest[j][0]\n",
    "            neighborhoods[i][j] = df_shortest['node'].values[j] + smallest_node_id\n",
    "\n",
    "    #neighborhoods_dict[l]= neighborhoods.copy()\n",
    "    if l_ind ==0:\n",
    "        neighborhoods_all = neighborhoods\n",
    "    else:\n",
    "        neighborhoods_all = np.r_[neighborhoods_all, neighborhoods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the adj matrix and the nodes:\n",
    "df_subset_adj = adj_dict[1]\n",
    "df_subset_nodes = df_node_label[df_node_label.graph_ind==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_graph_dict = dfadj_to_dict(df_subset_adj)\n",
    "temp_graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj_dict_by_graphId = create_adj_dict_by_graphId(df_adj, df_node_label)\n",
    "adj_coomatrix_by_graphId = create_adj_coomatrix_by_graphId(adj_dict_by_graphId, df_node_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_node_label = pd.concat([df_node_label, pd.Series(cano_label, dtype=int, name='cano_label')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighborhoods_graph = make_neighbor(adj_coomatrix_by_graphId, df_node_label, WIDTH_W=18, RECEPTIVE_FIELD_SIZE_K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_node_label.graph_ind.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node_label.graph_ind.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_node_label = pd.concat([df_node_label, pd.Series(cano_label, dtype=int, name='cano_label')], axis=1)\n",
    "\n",
    "neighborhoods_graph = make_neighbor(adj_coomatrix_by_graphId, df_node_label, WIDTH_W=WIDTH_W, RECEPTIVE_FIELD_SIZE_K=RECEPTIVE_FIELD_SIZE_K)\n",
    "result_tensor = tensor(neighborhoods_graph, WIDTH_W, RECEPTIVE_FIELD_SIZE_K, df_node_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_ranges = np.cumsum([0] + df_graph_ind.groupby('graph_ind').count().node.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_idx = 4\n",
    "list_nodes_per_graph = list(range(idx_ranges[graph_idx],idx_ranges[graph_idx+1]))\n",
    "adj_1 = df_adj[df_adj['from'].isin(list_nodes_per_graph) | df_adj['to'].isin(list_nodes_per_graph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = nx.Graph()\n",
    "g1.add_edges_from(adj_1.values)\n",
    "nx.draw(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(df_node_label.label.unique())\n",
    "print('number of features : {}'.format(num_features))\n",
    "data_in_patchysan = Patchy_san.main(WIDTH_W=18, RECEPTIVE_FIELD_SIZE_K=10, datasetname='MUTAG')\n",
    "data_in_patchysan.shape[3]\n",
    "#final_labels = mutag.get_graph_label().graph_label.values\n",
    "#final_labels = pd.get_dummies(final_labels).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_name = 'MUTAG'\n",
    "GAMMA_ENV = os.environ['GAMMA_DATA_ROOT']\n",
    "root_gamma_path = GAMMA_ENV+'Samples'\n",
    "node_label_filename =  '{0}/{0}_node_labels.txt'.format(dataset_name)\n",
    "node_label_path = os.path.join(root_gamma_path, node_label_filename)\n",
    "pd.read_csv(node_label_path , delimiter=' ',header=None,index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_subset_adj(df_adj, df_node_label,graph_label_num):\n",
    "    df_glabel = df_node_label[df_node_label.graph_label == graph_label_num ]\n",
    "    index_of_glabel = (df_adj['to'].isin(df_glabel.node) & df_adj['from'].isin(df_glabel.node))\n",
    "    return df_adj[index_of_glabel]\n",
    "\n",
    "def get_smallest_node_id_from_adj(df_adj):\n",
    "    return min(df_adj['to'].min(), df_adj['from'].min())\n",
    "\n",
    "\n",
    "def create_adj_dict_by_graphId(df_adj, df_node_label):\n",
    "    '''\n",
    "    input: df_node_label\n",
    "    return: {1: {0:[0,2,5]}} = {graphId: {nodeId:[node,node,node]}}\n",
    "    '''\n",
    "    adj_dict_by_graphId ={}\n",
    "    unique_graph_labels = df_node_label.graph_label.unique()\n",
    "    for l in unique_graph_labels:\n",
    "        df_subset_adj = get_subset_adj(df_adj, df_node_label, graph_label_num=l)        \n",
    "        smallest_node_id = get_smallest_node_id_from_adj(df_subset_adj)\n",
    "        df_subset_adj -= smallest_node_id\n",
    "        adj_dict_by_graphId[l] = df_subset_adj\n",
    "    return adj_dict_by_graphId\n",
    "\n",
    "\n",
    "def canonical_labeling(adj_dict_by_graphId, df_node_label, df_adj):\n",
    "    all_canonical_labels =[]\n",
    "    unique_graph_labels = df_node_label.graph_label.unique()\n",
    "    for l in unique_graph_labels:\n",
    "        df_subset_adj = adj_dict_by_graphId[l]\n",
    "        df_subset_nodes = df_node_label[df_node_label.graph_label==l]        \n",
    "        temp_graph_dict = utils.dfadj_to_dict(df_subset_adj)\n",
    "        nauty_graph = nauty.Graph(len(temp_graph_dict), adjacency_dict=temp_graph_dict)\n",
    "        canonical_labeling = nauty.canonical_labeling(nauty_graph)        \n",
    "        canonical_labeling = [df_subset_nodes.label.values[i] for i in canonical_labeling] ###\n",
    "        all_canonical_labels += canonical_labeling\n",
    "    return all_canonical_labels\n",
    "\n",
    "\n",
    "def create_adj_coomatrix_by_graphId(adj_dict_by_graphId, df_node_label):\n",
    "    \"\"\"\n",
    "    return: a coomatrix per graphId\n",
    "    \"\"\"\n",
    "    \n",
    "    adj_coomatrix_by_graphId ={}\n",
    "    unique_graph_labels = df_node_label.graph_label.unique()\n",
    "    for l in unique_graph_labels:\n",
    "        df_subset_adj = adj_dict_by_graphId[l]\n",
    "        df_subset_node_label = df_node_label[df_node_label.graph_label == l]\n",
    "        adjacency = coo_matrix(( np.ones(len(df_subset_adj)), \n",
    "                                (df_subset_adj.iloc[:,0].values, df_subset_adj.iloc[:,1].values) ), \n",
    "                                 shape=(len(df_subset_node_label), len(df_subset_node_label))\n",
    "                              )\n",
    "        adj_coomatrix_by_graphId[l]=adjacency\n",
    "    return adj_coomatrix_by_graphId\n",
    "\n",
    "def make_neighbor(adj_coomatrix_by_graphId, df_node_label, WIDTH_W):\n",
    "    \n",
    "    \"\"\"\n",
    "    return: a dictionary with the shape of {graphId:[matrix: node x neighbor]} \n",
    "    The size of 2D matrix is (Node number) x (RECEPTIVE_FIELD_SIZE_K). \n",
    "    \"\"\"\n",
    "    \n",
    "    neighborhoods_dict=dict()\n",
    "    \n",
    "    unique_graph_labels = df_node_label.graph_label.unique()\n",
    "    for l in unique_graph_labels:\n",
    "        adjacency = adj_coomatrix_by_graphId[l]\n",
    "        graph = nx.from_numpy_matrix(adjacency.todense())\n",
    "        \n",
    "        # Create the neighbors with -1 for neighbor assemble.\n",
    "        #After this, if the RECEPTIVE_FIELD_SIZE_K exceeds the number of WIDTH_W, then fill them with -1\n",
    "        neighborhoods = np.zeros((WIDTH_W, RECEPTIVE_FIELD_SIZE_K), dtype=np.int32)\n",
    "        neighborhoods.fill(-1) \n",
    "        \n",
    "        df_sequence = df_node_label[df_node_label.graph_label == l]\n",
    "        df_sequence = df_sequence.sort_values(by='cano_label')\n",
    "        smallest_node_id = df_sequence.node.min()\n",
    "                \n",
    "        # CUT GRAPH BY THRESHOLD of cano_label ''' Top width w elements of V according to labeling  '''\n",
    "        df_sequence = df_sequence.iloc[:WIDTH_W,:]\n",
    "        df_sequence['node'] = df_sequence.node.values  - smallest_node_id        \n",
    "        \n",
    "        for i, node in enumerate(df_sequence.node):\n",
    "            #shortest = nx.single_source_dijkstra_path_length(graph, node).items()\n",
    "            df_shortest = pd.DataFrame.from_dict(nx.single_source_dijkstra_path_length(graph, node),\n",
    "                                                 orient='index') #\n",
    "            df_shortest.columns =['distance'] #\n",
    "            df_shortest['node'] = df_shortest.index.values #\n",
    "            df_shortest = pd.merge(df_node_label, df_shortest, on='node', how='right') #\n",
    "            \n",
    "            # Sort by distance and then by cano_label            \n",
    "            df_shortest = df_shortest.sort_values(by=['distance','cano_label']) #\n",
    "            df_shortest = df_shortest.iloc[:RECEPTIVE_FIELD_SIZE_K,:] #\n",
    "            #shortest = sorted(shortest, key=lambda v: v[1])            \n",
    "            #shortest = shortest[:RECEPTIVE_FIELD_SIZE_K]\n",
    "            for j in range(0, min(RECEPTIVE_FIELD_SIZE_K, len(df_shortest))):\n",
    "                #neighborhoods[i][j] = shortest[j][0]\n",
    "                neighborhoods[i][j] = df_shortest['node'].values[j]\n",
    "                \n",
    "        neighborhoods_dict[l]= neighborhoods.copy()\n",
    "    return neighborhoods_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "now = time.time()\n",
    "\n",
    "#NUM_NODES \n",
    "LABEL_THRESHOLD = 2 #threshold of canonical label\n",
    "RECEPTIVE_FIELD_SIZE_K = 20 #''' Receptive Field Size'''\n",
    "WIDTH_W = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main (Timing starts here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj_dict_by_graphId = create_adj_dict_by_graphId(df_adj, df_node_label)\n",
    "cano_label = canonical_labeling(adj_dict_by_graphId, df_node_label, df_adj)\n",
    "df_node_label = pd.concat([df_node_label, pd.Series(cano_label, dtype=int, name='cano_label')],  axis=1)\n",
    "\n",
    "#cert_list = [i for i in (nauty.certificate(nauty_graph))]\n",
    "# '''canonical_labeling = [df_node_label.label.values[i] for i in canonical_labeling]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Show the frequency of labels to make threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# #How to select top w elements of V according to labeling  \n",
    "df_node_label.cano_label.value_counts().plot(kind='bar')\n",
    "df_node_label.cano_label.value_counts().sort_index().plot(kind='bar',  figsize=(14,5))\n",
    "plt.title('Number of nodes by labeling')\n",
    "plt.xlabel('Labeling')\n",
    "plt.ylabel('Number of nodes')\n",
    "\n",
    "_SUM_ALL_NODES = df_node_label.shape[0]\n",
    "plt.twinx()\n",
    "plt.ylabel(\"Cummlative Sum Rate\", color=\"r\")\n",
    "plt.tick_params(axis=\"y\", labelcolor=\"r\")\n",
    "plt.plot(df_node_label.cano_label.value_counts().sort_index().index, \n",
    "         df_node_label.cano_label.value_counts().sort_index().cumsum() /_SUM_ALL_NODES, \"r-\", linewidth=2)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get several nodes with a condition of cano_label (sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj_coomatrix_by_graphId = create_adj_coomatrix_by_graphId(adj_dict_by_graphId, df_node_label)\n",
    "neighborhoods_graph = make_neighbor(adj_coomatrix_by_graphId, df_node_label, WIDTH_W=WIDTH_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things about tensorflow constraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "neighborhoods[graphId]: This represents the matrix of (nodes x neighbor).\n",
    "nodes: This represents the matrix of (nodes x features).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = df_node_label['label'].unique()\n",
    "num_features = len(feature_list)\n",
    "\n",
    "def main_timing(graph_id):\n",
    "    neighborhoods = tf.constant(neighborhoods_graph[graph_id], dtype=tf.int32)\n",
    "    sparse_df = pd.get_dummies(df_node_label.loc[df_node_label.graph_label==graph_id].label, \n",
    "                               columns=feature_list,\n",
    "                               sparse=True\n",
    "                              )\n",
    "    \n",
    "    #### Reindex and transporse to get columns of get dummy #########\n",
    "    sparse_df = sparse_df.T.reindex(feature_list).T.fillna(0)\n",
    "    nodes = tf.constant(sparse_df.values, dtype=tf.int32 )\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        data = tf.reshape(neighborhoods, [-1])\n",
    "        i = tf.maximum(data, 0)\n",
    "        i_list = i.eval()\n",
    "        #print(i_list)\n",
    "        #print('')\n",
    "\n",
    "        for ind, i in enumerate(i_list):\n",
    "            if ind ==0: \n",
    "                positive = tf.strided_slice(nodes, [i], [i+1], [1])\n",
    "                #positive = tf.constant(temp)\n",
    "            else:\n",
    "                temp = tf.strided_slice(nodes, [i], [i+1], [1])\n",
    "                positive = tf.concat([positive,temp],axis=0)\n",
    "\n",
    "        negative = tf.zeros([positive.shape[0], positive.shape[1]], dtype= tf.int32)\n",
    "\n",
    "        #print ('shape', data.shape, negative.shape, positive.shape)\n",
    "        #print ( data, negative, positive)\n",
    "\n",
    "        # padding with 0 here because -1 indicates there is no neighbor nodes.\n",
    "        ret = tf.where(data < 0, negative, positive)\n",
    "        #print('padding done')\n",
    "\n",
    "\n",
    "        ret = tf.reshape(ret, \n",
    "                         [neighborhoods.shape[0], \n",
    "                          RECEPTIVE_FIELD_SIZE_K, # This is equals to neighborhoods.shape[1]\n",
    "                          num_features])\n",
    "        #print (key, 'ret.shape: ',ret.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#stop stp stp\n",
    "for key in tqdm(adj_dict_by_graphId.keys()):\n",
    "    main_timing(key)\n",
    "\n",
    "print ('time passed in seconds', (\"%.2f\"%(time.time() - now)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
